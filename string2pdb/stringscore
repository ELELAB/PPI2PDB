#!/usr/bin/env python3

# STRING2PDB
# Copyright (C) 2024  Eleni Kiachaki and Matteo Tiberti, Cancer Structural Biology, Danish Cancer Institute
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

import requests
import argparse
import pandas as pd
from io import StringIO
import re

# Load the aliases file:
# I assume the file must be moved to /data/databases/ 
aliases_df = pd.read_csv('/data/user/elenikia/9606.protein.aliases.v12.0.txt', sep='\t', header=None, names=['STRING_ID', 'Alias', 'Source'])

def string2uniprot(string_id):

    # Regex to check if the format matches a reviewed Uniprot entry:
    reviewed_pattern = re.compile(r'^[A-Z][0-9][A-Z0-9]{4}$')  
   
    # Filter rows for STRING ID and 'Ensembl_HGNC_uniprot_ids' source:
    ids_rows = aliases_df[(aliases_df['STRING_ID'] == string_id) & 
                      (aliases_df['Source'] == 'Ensembl_HGNC_uniprot_ids')]

    # If no results, check for Uniprot_AC alternatively:
    if ids_rows.empty:
        AC_rows = aliases_df[(aliases_df['STRING_ID'] == string_id) & 
                      (aliases_df['Source'] == 'UniProt_AC')]

        uniprot_acs = AC_rows['Alias'].tolist()

        if not uniprot_acs:
            print(f"Error: No Uniprot AC found for String ID {string_id}. Exiting")
            exit(1)

        # Filter UniProt ACs that match the reviewed pattern:
        reviewed_acs = [ac for ac in uniprot_acs if reviewed_pattern.match(ac)]

        if not reviewed_acs:
            print(f"Error: No valid reviewed UniProt AC found for STRING ID {string_id}")
            exit(1)

        if len(reviewed_acs) > 1:
            # Here (unlike what I do when reviewed_ids >= 1), I return only the most recent one, 
            # because the rest are either unreviewed, or older versions.
            # Return the most recent one:
            reviewed_acs.sort()
            most_recent_ac = reviewed_acs[-1]
        else:
            # Return the Unique:
            reviewed_acs[0]
        
        return [most_recent_ac]
    
    # Extract the UniProt IDs:
    uniprot_ids = ids_rows['Alias'].tolist()
    
    # Filter UniProt IDs that match the reviewed pattern:
    reviewed_ids = [uid for uid in uniprot_ids if reviewed_pattern.match(uid)]

    # Check if any reviewed IDs were found:
    if not reviewed_ids:
        print(f"Error: No valid reviewed UniProt ID found for STRING ID {string_id}")
        exit(1)

        # The script continues here if reviewed_ids >= 1.
        # Not sure if here I should keep all of them and print them in different rows, but I think Mentha does it this way.
        # See example of target:TP53 :For the interactor CDKN2A Mentha lists both IDs as interactors: Q8N726, P42771 in different rows
        # In that case, it means that different proteins(not just isoforms) are encoded by same gene, so all of them
        # should be present as different interactors.
    
    return reviewed_ids


def main():
    parser = argparse.ArgumentParser(
        description="Retrieval of interaction data from the STRING database for a given gene name."
    )
    parser.add_argument(
        "identifier", 
        type=str,
        help="HUGO Gene name to retrieve interactors for."
    )
    parser.add_argument(
        "-t", 
        "--threshold",
        type=float,
        default=0.7,
        help="Minimum STRING confidence score for interaction filtering (default: 0.7)."
    )
    parser.add_argument(
        "-n",
        "--network",
        type=str,
        default="physical",
        choices=["functional", "physical"],
        help="STRING network type to be used: 'physical' for physical interactions, 'functional' for all interactions (default: 'physical')."
    )

    args = parser.parse_args()
    
    base_url = "https://string-db.org/api/tsv/get_string_ids"
    params = {
        'identifier': args.identifier,  
        'species': 9606,         
        'limit': 0,  
        'caller_identity': "MAVISp_web_app"     
    }

    try:
        string_response = requests.get(base_url, params=params)
        string_response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"Error: Unable to get data ({e})")
        exit(1)

    # Read tsv data into pandas dataframe:
    data = pd.read_csv(StringIO(string_response.text), sep='\t')

    # Convert each String_Id to UniProt AC and store in a new column:
    data['UniProt_AC'] = data['stringId'].apply(string2uniprot)

    # Explode the DataFrame for rows where UniProt_AC has multiple values:
    data = data.explode('UniProt_AC')

    # Check if identifier is in the converted UniProt_AC column:
    if args.identifier not in data['UniProt_AC'].values:
        print(f"Error: No STRING identifier found for {args.identifier} in the results.")
        exit(1)

    # Initialize matching_row to None:
    matching_row = None 

    # Check for multiple rows with different STRING IDs
    unique_string_ids = data['stringId'].nunique()

    if unique_string_ids > 1:
        print(f"Warning: Multiple STRING IDs found for {args.identifier}. Proceeding with the String ID whose UniProt AC matches the input identifier:{args.identifier}.")
        # Select the row where UniProt_AC matches args.identifier
        matching_row = data[data['UniProt_AC'] == args.identifier]
        string_id = matching_row.iloc[0]['stringId']
            
    else:
        # Only one unique STRING ID, proceed with it:
        string_id = data.iloc[0]['stringId']

    # Get interactors from STRING API
    interactors_url = "https://string-db.org/api/tsv/interaction_partners"
    interactors_params = {
        'identifier': string_id,  
        'species': 9606,
        'required_score': args.threshold,
        'limit': 0,
        'network_type': args.network,
        'caller_identity': "MAVISp_web_app"
    }

    try:
        interactors_response = requests.get(interactors_url, params=interactors_params)
        interactors_response.raise_for_status()
    except requests.exceptions.RequestException as e:
        print(f"Error: Unable to get interaction data ({e})")
        exit(1)

    # Read tsv data into pandas dataframe:
    interactors_df = pd.read_csv(StringIO(interactors_response.text), sep='\t')

    
    # Filter interactors with both score >= threshold and dscore > 0 
    # With database score > 0: No retrieval of unreviewed interactors
    filtered_interactors = interactors_df[(interactors_df['score'] >= args.threshold) & (interactors_df['dscore'] > 0)].copy()

    # Assign new columns:
    filtered_interactors.loc[:, 'Interactor_UniProt_AC'] = filtered_interactors['stringId_B'].apply(string2uniprot)
    filtered_interactors['Target_Uniprot_AC'] = args.identifier

    # Explode DataFrame for UniProt AC entries if multiple reviewed IDs found:
    filtered_interactors = filtered_interactors.explode('Interactor_UniProt_AC')

    if filtered_interactors.empty:
        print(f"No interactors found with score >= {args.threshold}.")
        exit(0)

    # Extract columns:
    interactors = filtered_interactors[['preferredName_A', 'stringId_A', 'Target_Uniprot_AC', 'preferredName_B', 'stringId_B', 'Interactor_UniProt_AC',
                                        'score', 'escore', 'dscore', 'tscore']]

    # Output CSV file:
    output_file = f"{args.identifier}_string_interactors.csv"
    interactors.to_csv(output_file, index=False, header=['Target_protein', 'Target_id', 'Target_Uniprot_AC', 'Interactor', 'Interactor_id', 'Interactor_UniProt_AC',
                                                         'String_score', 'escore', 'dscore', 
                                                         'tscore'])

    print(f"Results saved to {output_file}")

if __name__ == "__main__":
    main()
